{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "import io\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sign Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"sign_detection/images/test/\"\n",
    "text_img_path = \"sign_detection/images/test/\"\n",
    "annot_path = \"sign_detection/annotations/test_annotations.json\"\n",
    "tfrecord_path = \"sign_detection/annotations/test.record\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('output_path', '', 'sign_detection/annotations/test.record')\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(annot):\n",
    "    # TODO(user): Populate the following variables from your example.\n",
    "    \n",
    "    fname = annot['filename']\n",
    "    \n",
    "    with tf.gfile.GFile(os.path.join(img_path, '{}'.format(fname)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "    \n",
    "#     print(type(encoded_jpg))\n",
    "#     print(type(encoded_jpg_io))\n",
    "#     print(type(image))\n",
    "\n",
    "    #height = None # Image height\n",
    "    #width = None # Image width\n",
    "    filename = fname.encode('utf8') # Filename of the image. Empty if image is not from file\n",
    "    encoded_image_data = encoded_jpg # Encoded image bytes\n",
    "    image_format = b'jpg' # b'jpeg' or b'png'\n",
    "    \n",
    "    xmins, ymins, xmaxs, ymaxs = [], [], [], []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "    count = 0\n",
    "    for box in annot['regions']:\n",
    "        if box[\"shape_attributes\"][\"name\"] == \"rect\":\n",
    "            count += 1\n",
    "            xmins.append(box[\"shape_attributes\"][\"x\"])\n",
    "            ymins.append(box[\"shape_attributes\"][\"y\"])\n",
    "            xmaxs.append(box[\"shape_attributes\"][\"x\"] + box[\"shape_attributes\"][\"width\"])\n",
    "            ymaxs.append(box[\"shape_attributes\"][\"y\"] + box[\"shape_attributes\"][\"height\"])\n",
    "            classes_text.append('sign'.encode('utf8'))\n",
    "            classes.append(1)\n",
    "            \n",
    "    if len(xmins) == 0:\n",
    "        xmins = []\n",
    "        xmaxs = []\n",
    "        ymins = []\n",
    "        ymaxs = []\n",
    "        classes_text = []\n",
    "        classes = []\n",
    "    else:\n",
    "        xmins = [xmin / width for xmin in xmins] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "        xmaxs = [xmax / width for xmax in xmaxs] # List of normalized right x coordinates in bounding box\n",
    "                 # (1 per box)\n",
    "        ymins = [ymin / height for ymin in ymins] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "        ymaxs = [ymax / height for ymax in ymaxs] # List of normalized bottom y coordinates in bounding box\n",
    "                 # (1 per box)\n",
    "        #classes_text = ['sign'.encode('utf8')] # List of string class name of bounding box (1 per box)\n",
    "        #classes = [1] # List of integer class id of bounding box (1 per box)\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(filename),\n",
    "      'image/source_id': dataset_util.bytes_feature(filename),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "      'image/format': dataset_util.bytes_feature(image_format),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    \n",
    "    #if count > 2:\n",
    "    #    print(tf_example)\n",
    "    return tf_example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.python_io.TFRecordWriter(tfrecord_path)\n",
    "\n",
    "# TODO(user): Write code to read in your dataset to examples variable\n",
    "\n",
    "with open(annot_path) as rb:\n",
    "    annots = json.load(rb)\n",
    "\n",
    "for annot in annots:\n",
    "    tf_example = create_tf_example(annot)\n",
    "    break\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n"
     ]
    }
   ],
   "source": [
    "print(len(annots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"sign_detection/images/test/\"\n",
    "text_img_path = \"sign_detection/images_text_detection/test/\"\n",
    "annot_path = \"sign_detection/annotations/test_annotations.json\"\n",
    "tfrecord_path = \"sign_detection/annotations/test_text.record\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('output_path', '', 'sign_detection/annotations/test_text.record')\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(annot):\n",
    "    fname = annot['filename']\n",
    "    \n",
    "    with tf.gfile.GFile(os.path.join(img_path, '{}'.format(fname)), 'rb') as fid:\n",
    "        encoded_img = fid.read()\n",
    "    encoded_img_io = io.BytesIO(encoded_img)\n",
    "    \n",
    "    sign_count = 0\n",
    "    tf_list = []\n",
    "    \n",
    "    for box_sign in annot['regions']:\n",
    "        if box_sign[\"shape_attributes\"][\"name\"] == \"rect\":\n",
    "            xmin_sign = box_sign[\"shape_attributes\"][\"x\"]\n",
    "            ymin_sign = box_sign[\"shape_attributes\"][\"y\"]\n",
    "            xmax_sign = box_sign[\"shape_attributes\"][\"x\"] + box_sign[\"shape_attributes\"][\"width\"]\n",
    "            ymax_sign = box_sign[\"shape_attributes\"][\"y\"] + box_sign[\"shape_attributes\"][\"height\"]\n",
    "            \n",
    "            fname_box = fname[:-4] + \"_\" + str(sign_count) + \".jpg\"\n",
    "            \n",
    "            image_sign = Image.open(encoded_img_io)\n",
    "            cropped_img = image_sign.crop((xmin_sign, ymin_sign, xmax_sign, ymax_sign))\n",
    "            cropped_img.save(text_img_path + fname_box)\n",
    "            \n",
    "            with tf.gfile.GFile(os.path.join(text_img_path, '{}'.format(fname_box)), 'rb') as fid:\n",
    "                encoded_jpg = fid.read()\n",
    "            encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "            image = Image.open(encoded_jpg_io)\n",
    "            width, height = image.size\n",
    "            \n",
    "            filename = fname_box.encode('utf8') # Filename of the image. Empty if image is not from file\n",
    "            encoded_image_data = encoded_jpg # Encoded image bytes\n",
    "            image_format = b'jpg' # b'jpeg' or b'png'\n",
    "            \n",
    "            xmins, ymins, xmaxs, ymaxs = [], [], [], []\n",
    "            classes_text = []\n",
    "            classes = []\n",
    "            \n",
    "            #print(\"Sign Count:\", sign_count)\n",
    "            \n",
    "            for box in annot['regions']:\n",
    "                if box[\"shape_attributes\"][\"name\"] == \"polygon\":\n",
    "                    x_points = box[\"shape_attributes\"][\"all_points_x\"]\n",
    "                    y_points = box[\"shape_attributes\"][\"all_points_y\"]\n",
    "                    \n",
    "                    x_points = [int(xp.split('-')[0]) if type(xp) == str else xp for xp in x_points]\n",
    "                    y_points = [int(yp.split('-')[0]) if type(yp) == str else yp for yp in y_points]\n",
    "                    \n",
    "                    xmin = min(x_points)\n",
    "                    xmax = max(x_points)\n",
    "                    ymin = min(y_points)\n",
    "                    ymax = max(y_points)\n",
    "                    \n",
    "                    #center_x = (xmin + xmax)/2\n",
    "                    #center_y = (ymin + ymax)/2\n",
    "                    \n",
    "                    #print(x_points, y_points)\n",
    "                    #print(\"Poly:\",xmin, xmax, ymin, ymax)\n",
    "                    #print(\"Sign:\",xmin_sign, xmax_sign, ymin_sign, ymax_sign)\n",
    "                    \n",
    "                    if (xmin >= xmin_sign and ymin >= ymin_sign and xmax <= xmax_sign and ymax <= ymax_sign):\n",
    "                        xmin_rel = abs(xmin - xmin_sign)\n",
    "                        ymin_rel = abs(ymin - ymin_sign)\n",
    "                        xmax_rel = abs(xmax - xmin_sign)\n",
    "                        ymax_rel = abs(ymax - ymin_sign)\n",
    "                        \n",
    "                        xmins.append(xmin_rel)\n",
    "                        ymins.append(ymin_rel)\n",
    "                        xmaxs.append(xmax_rel)\n",
    "                        ymaxs.append(ymax_rel)\n",
    "                        classes_text.append('text'.encode('utf8'))\n",
    "                        classes.append(1)\n",
    "                            \n",
    "            if len(xmins) == 0:\n",
    "                xmins = []\n",
    "                xmaxs = []\n",
    "                ymins = []\n",
    "                ymaxs = []\n",
    "                classes_text = []\n",
    "                classes = []\n",
    "            else:\n",
    "                xmins = [xmin / width for xmin in xmins] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "                xmaxs = [xmax / width for xmax in xmaxs] # List of normalized right x coordinates in bounding box\n",
    "                         #(1 per box)\n",
    "                ymins = [ymin / height for ymin in ymins] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "                ymaxs = [ymax / height for ymax in ymaxs] # List of normalized bottom y coordinates in bounding box\n",
    "                         #(1 per box)\n",
    "                    \n",
    "                tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                  'image/height': dataset_util.int64_feature(height),\n",
    "                  'image/width': dataset_util.int64_feature(width),\n",
    "                  'image/filename': dataset_util.bytes_feature(filename),\n",
    "                  'image/source_id': dataset_util.bytes_feature(filename),\n",
    "                  'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "                  'image/format': dataset_util.bytes_feature(image_format),\n",
    "                  'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "                  'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "                  'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "                  'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "                  'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "                  'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "                }))\n",
    "                \n",
    "                tf_list.append(tf_example)\n",
    "            \n",
    "            #print(tf_example)\n",
    "            \n",
    "            #tf_list.append(tf_example)\n",
    "            \n",
    "            sign_count += 1\n",
    "            \n",
    "    print(\"Image:\", fname, \"Signs:\", sign_count)\n",
    "    \n",
    "#     if sign_count > 1:\n",
    "#         print(tf_list)\n",
    "   \n",
    "    return tf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 1382.jpg Signs: 3\n",
      "Image: 286.jpg Signs: 2\n",
      "Image: 941.jpg Signs: 2\n",
      "Image: 519.jpg Signs: 2\n",
      "Image: 196.jpg Signs: 1\n",
      "Image: 1385.jpg Signs: 3\n",
      "Image: 352.jpg Signs: 1\n",
      "Image: 530.jpg Signs: 1\n",
      "Image: 1396.jpg Signs: 2\n",
      "Image: 747.jpg Signs: 2\n",
      "Image: 1042.jpg Signs: 2\n",
      "Image: 1328.jpg Signs: 1\n",
      "Image: 191.jpg Signs: 1\n",
      "Image: 1209.jpg Signs: 1\n",
      "Image: 738.jpg Signs: 1\n",
      "Image: 293.jpg Signs: 2\n",
      "Image: 807.jpg Signs: 2\n",
      "Image: 940.jpg Signs: 2\n",
      "Image: 1079.jpg Signs: 1\n",
      "Image: 635.jpg Signs: 1\n",
      "Image: 522.jpg Signs: 1\n",
      "Image: 1367.jpg Signs: 3\n",
      "Image: 515.jpg Signs: 1\n",
      "Image: 719.jpg Signs: 1\n",
      "Image: 306.jpg Signs: 3\n",
      "Image: 1295.jpg Signs: 3\n",
      "Image: 898.jpg Signs: 1\n",
      "Image: 287.jpg Signs: 2\n",
      "Image: 935.jpg Signs: 2\n",
      "Image: 1432.jpg Signs: 1\n",
      "Image: 1027.jpg Signs: 2\n",
      "Image: 727.jpg Signs: 1\n",
      "Image: 1041.jpg Signs: 2\n",
      "Image: 80.jpg Signs: 1\n",
      "Image: 76.jpg Signs: 1\n",
      "Image: 1283.jpg Signs: 2\n",
      "Image: 1402.jpg Signs: 2\n",
      "Image: 359.jpg Signs: 1\n",
      "Image: 292.jpg Signs: 2\n",
      "Image: 804.jpg Signs: 1\n",
      "Image: 1370.jpg Signs: 3\n",
      "Image: 728.jpg Signs: 1\n",
      "Image: 285.jpg Signs: 2\n",
      "Image: 721.jpg Signs: 1\n",
      "Image: 296.jpg Signs: 3\n",
      "Image: 1029.jpg Signs: 2\n",
      "Image: 1369.jpg Signs: 3\n",
      "Image: 1389.jpg Signs: 2\n",
      "Image: 732.jpg Signs: 1\n",
      "Image: 639.jpg Signs: 1\n",
      "Image: 1377.jpg Signs: 3\n",
      "Image: 362.jpg Signs: 1\n",
      "Image: 1028.jpg Signs: 2\n",
      "Image: 1043.jpg Signs: 2\n",
      "Image: 1368.jpg Signs: 3\n",
      "Image: 634.jpg Signs: 1\n",
      "Image: 531.jpg Signs: 1\n",
      "Image: 1130.jpg Signs: 1\n",
      "Image: 1341.jpg Signs: 1\n",
      "Image: 520.jpg Signs: 2\n",
      "Image: 1376.jpg Signs: 0\n",
      "Image: 725.jpg Signs: 1\n",
      "Image: 1391.jpg Signs: 2\n",
      "Image: 947.jpg Signs: 2\n",
      "Image: 735.jpg Signs: 1\n",
      "Image: 1204.jpg Signs: 1\n",
      "Image: 943.jpg Signs: 2\n",
      "Image: 1512.jpg Signs: 1\n",
      "Image: 1339.jpg Signs: 1\n",
      "Image: 528.jpg Signs: 1\n",
      "Image: 733.jpg Signs: 1\n",
      "Image: 305.jpg Signs: 3\n",
      "Image: 518.jpg Signs: 2\n",
      "Image: 74.jpg Signs: 1\n",
      "Image: 1201.jpg Signs: 1\n",
      "Image: 1331.jpg Signs: 2\n",
      "Image: 938.jpg Signs: 2\n",
      "Image: 894.jpg Signs: 1\n",
      "Image: 526.jpg Signs: 1\n",
      "Image: 1448.jpg Signs: 1\n",
      "Image: 1333.jpg Signs: 2\n",
      "Image: 1371.jpg Signs: 3\n",
      "Image: 897.jpg Signs: 1\n",
      "Image: 1403.jpg Signs: 2\n",
      "Image: 1400.jpg Signs: 2\n",
      "Image: 1082.jpg Signs: 1\n",
      "Image: 1287.jpg Signs: 1\n",
      "Image: 936.jpg Signs: 2\n",
      "Image: 1336.jpg Signs: 1\n",
      "Image: 1334.jpg Signs: 1\n",
      "Image: 1327.jpg Signs: 1\n",
      "Image: 1332.jpg Signs: 2\n",
      "Image: 1202.jpg Signs: 1\n",
      "Image: 288.jpg Signs: 2\n",
      "Image: 1026.jpg Signs: 2\n",
      "Image: 890.jpg Signs: 1\n",
      "Image: 1384.jpg Signs: 3\n",
      "Image: 743.jpg Signs: 2\n",
      "Image: 1383.jpg Signs: 3\n",
      "Image: 509.jpg Signs: 1\n",
      "Image: 514.jpg Signs: 1\n",
      "Image: 636.jpg Signs: 1\n",
      "Image: 1030.jpg Signs: 1\n",
      "Image: 523.jpg Signs: 1\n",
      "Image: 1449.jpg Signs: 1\n",
      "Image: 1335.jpg Signs: 1\n",
      "Image: 1019.jpg Signs: 2\n",
      "Image: 197.jpg Signs: 1\n",
      "Image: 1022.jpg Signs: 2\n",
      "Image: 73.jpg Signs: 1\n",
      "Image: 529.jpg Signs: 1\n",
      "Image: 299.jpg Signs: 3\n",
      "Image: 283.jpg Signs: 2\n",
      "Image: 202.jpg Signs: 1\n",
      "Image: 1513.jpg Signs: 2\n",
      "Image: 1514.jpg Signs: 1\n",
      "Image: 744.jpg Signs: 2\n",
      "Image: 736.jpg Signs: 1\n",
      "Image: 1511.jpg Signs: 1\n",
      "Image: 1078.jpg Signs: 1\n",
      "Image: 720.jpg Signs: 1\n",
      "Image: 525.jpg Signs: 1\n",
      "Image: 946.jpg Signs: 2\n",
      "Image: 1289.jpg Signs: 1\n",
      "Image: 942.jpg Signs: 2\n",
      "Image: 1338.jpg Signs: 1\n",
      "Image: 803.jpg Signs: 1\n",
      "Image: 300.jpg Signs: 3\n",
      "Image: 1286.jpg Signs: 1\n",
      "Image: 1397.jpg Signs: 3\n",
      "Image: 1290.jpg Signs: 1\n",
      "Image: 729.jpg Signs: 1\n",
      "Image: 1394.jpg Signs: 2\n",
      "Image: 1025.jpg Signs: 2\n",
      "Image: 1342.jpg Signs: 1\n",
      "Image: 1450.jpg Signs: 1\n",
      "Image: 1292.jpg Signs: 1\n",
      "Image: 739.jpg Signs: 1\n",
      "Image: 364.jpg Signs: 1\n",
      "Image: 513.jpg Signs: 1\n",
      "Image: 1388.jpg Signs: 2\n",
      "Image: 1045.jpg Signs: 2\n",
      "Image: 1034.jpg Signs: 1\n",
      "Image: 801.jpg Signs: 1\n",
      "Image: 199.jpg Signs: 1\n",
      "Image: 896.jpg Signs: 1\n",
      "Image: 1294.jpg Signs: 3\n",
      "Image: 510.jpg Signs: 1\n",
      "Image: 512.jpg Signs: 1\n",
      "Image: 1343.jpg Signs: 1\n",
      "Image: 751.jpg Signs: 2\n",
      "Image: 1395.jpg Signs: 2\n",
      "Image: 302.jpg Signs: 3\n",
      "Image: 749.jpg Signs: 2\n",
      "Image: 282.jpg Signs: 2\n",
      "Image: 276.jpg Signs: 2\n",
      "Image: 750.jpg Signs: 2\n",
      "Image: 1017.jpg Signs: 2\n",
      "Image: 1298.jpg Signs: 1\n",
      "Image: 1299.jpg Signs: 1\n",
      "Image: 298.jpg Signs: 3\n",
      "Image: 304.jpg Signs: 3\n",
      "Image: 360.jpg Signs: 1\n",
      "Image: 722.jpg Signs: 1\n",
      "Image: 1380.jpg Signs: 3\n",
      "Image: 748.jpg Signs: 2\n",
      "Image: 303.jpg Signs: 3\n",
      "Image: 1375.jpg Signs: 3\n",
      "Image: 1128.jpg Signs: 1\n",
      "Image: 1401.jpg Signs: 2\n",
      "Image: 734.jpg Signs: 1\n",
      "Image: 740.jpg Signs: 1\n",
      "Image: 284.jpg Signs: 2\n",
      "Image: 1404.jpg Signs: 2\n",
      "Image: 638.jpg Signs: 1\n",
      "Image: 1205.jpg Signs: 1\n",
      "Image: 1381.jpg Signs: 3\n",
      "Image: 1378.jpg Signs: 3\n",
      "Image: 193.jpg Signs: 1\n",
      "Image: 1031.jpg Signs: 1\n",
      "Image: 1379.jpg Signs: 3\n",
      "Image: 1433.jpg Signs: 1\n",
      "Image: 1374.jpg Signs: 3\n",
      "Image: 78.jpg Signs: 1\n",
      "Image: 895.jpg Signs: 1\n",
      "Image: 1200.jpg Signs: 1\n",
      "Image: 1080.jpg Signs: 1\n",
      "Image: 1044.jpg Signs: 2\n",
      "Image: 1372.jpg Signs: 3\n",
      "Image: 295.jpg Signs: 3\n",
      "Image: 279.jpg Signs: 2\n",
      "Image: 1023.jpg Signs: 2\n",
      "Image: 294.jpg Signs: 2\n",
      "Image: 350.jpg Signs: 1\n",
      "Image: 532.jpg Signs: 1\n",
      "Image: 1129.jpg Signs: 1\n",
      "Image: 297.jpg Signs: 3\n",
      "Image: 356.jpg Signs: 1\n",
      "Image: 517.jpg Signs: 2\n",
      "Image: 201.jpg Signs: 1\n",
      "Image: 1508.jpg Signs: 1\n",
      "Image: 1452.jpg Signs: 1\n",
      "Image: 1018.jpg Signs: 2\n",
      "Image: 944.jpg Signs: 2\n",
      "Image: 1288.jpg Signs: 1\n",
      "Image: 290.jpg Signs: 2\n",
      "Image: 1330.jpg Signs: 1\n",
      "Image: 200.jpg Signs: 1\n",
      "Image: 1390.jpg Signs: 2\n",
      "Image: 1040.jpg Signs: 2\n",
      "Image: 1386.jpg Signs: 3\n",
      "Image: 1293.jpg Signs: 1\n",
      "Image: 280.jpg Signs: 2\n",
      "Image: 726.jpg Signs: 1\n",
      "Image: 511.jpg Signs: 1\n",
      "Image: 737.jpg Signs: 1\n",
      "Image: 1337.jpg Signs: 1\n",
      "Image: 278.jpg Signs: 2\n",
      "Image: 275.jpg Signs: 2\n",
      "Image: 516.jpg Signs: 2\n",
      "Image: 349.jpg Signs: 1\n",
      "Image: 1033.jpg Signs: 1\n",
      "Image: 281.jpg Signs: 2\n",
      "Image: 1207.jpg Signs: 1\n",
      "Image: 1392.jpg Signs: 2\n",
      "Image: 351.jpg Signs: 1\n",
      "Image: 361.jpg Signs: 1\n",
      "Image: 1451.jpg Signs: 1\n",
      "Image: 1393.jpg Signs: 2\n",
      "Image: 1035.jpg Signs: 1\n",
      "Image: 805.jpg Signs: 1\n",
      "Image: 354.jpg Signs: 1\n",
      "Image: 307.jpg Signs: 3\n",
      "Image: 355.jpg Signs: 1\n",
      "Image: 633.jpg Signs: 1\n",
      "Image: 363.jpg Signs: 1\n",
      "Image: 731.jpg Signs: 1\n",
      "Image: 1297.jpg Signs: 1\n",
      "Image: 1016.jpg Signs: 1\n",
      "Image: 277.jpg Signs: 2\n",
      "Image: 79.jpg Signs: 1\n",
      "Image: 745.jpg Signs: 2\n",
      "Image: 1285.jpg Signs: 1\n",
      "Image: 892.jpg Signs: 1\n",
      "Image: 301.jpg Signs: 3\n",
      "Image: 521.jpg Signs: 2\n",
      "Image: 1510.jpg Signs: 1\n",
      "Image: 1431.jpg Signs: 1\n",
      "Image: 1509.jpg Signs: 1\n",
      "Image: 1021.jpg Signs: 2\n",
      "Image: 1340.jpg Signs: 1\n",
      "Image: 1020.jpg Signs: 2\n",
      "Image: 1284.jpg Signs: 1\n",
      "Image: 357.jpg Signs: 1\n",
      "Image: 806.jpg Signs: 2\n",
      "Image: 723.jpg Signs: 1\n",
      "Image: 934.jpg Signs: 2\n",
      "Image: 1081.jpg Signs: 1\n",
      "Image: 730.jpg Signs: 1\n",
      "Image: 1373.jpg Signs: 3\n",
      "Image: 189.jpg Signs: 1\n",
      "Image: 192.jpg Signs: 1\n",
      "Image: 808.jpg Signs: 1\n",
      "Image: 195.jpg Signs: 1\n",
      "Image: 1032.jpg Signs: 1\n",
      "Image: 637.jpg Signs: 1\n",
      "Image: 891.jpg Signs: 1\n",
      "Image: 1046.jpg Signs: 2\n",
      "Image: 742.jpg Signs: 1\n",
      "Image: 893.jpg Signs: 1\n",
      "Image: 1024.jpg Signs: 2\n",
      "Image: 1399.jpg Signs: 2\n",
      "Image: 746.jpg Signs: 2\n",
      "Image: 198.jpg Signs: 1\n",
      "Image: 939.jpg Signs: 2\n",
      "Image: 1206.jpg Signs: 1\n",
      "Image: 802.jpg Signs: 2\n",
      "Image: 937.jpg Signs: 2\n",
      "Image: 527.jpg Signs: 1\n",
      "Image: 358.jpg Signs: 1\n",
      "Image: 1291.jpg Signs: 1\n",
      "Image: 1430.jpg Signs: 1\n",
      "Image: 1203.jpg Signs: 1\n",
      "Image: 289.jpg Signs: 2\n",
      "Image: 1296.jpg Signs: 1\n",
      "Image: 353.jpg Signs: 1\n",
      "Image: 1398.jpg Signs: 2\n",
      "Image: 75.jpg Signs: 1\n",
      "Image: 1199.jpg Signs: 1\n",
      "Image: 945.jpg Signs: 2\n",
      "Image: 1387.jpg Signs: 3\n",
      "Image: 77.jpg Signs: 1\n",
      "Image: 724.jpg Signs: 1\n",
      "Image: 1329.jpg Signs: 1\n",
      "Image: 741.jpg Signs: 1\n",
      "Image: 1208.jpg Signs: 1\n",
      "Image: 524.jpg Signs: 1\n",
      "Image: 809.jpg Signs: 3\n",
      "Image: 190.jpg Signs: 1\n",
      "Image: 194.jpg Signs: 1\n",
      "Image: 291.jpg Signs: 2\n",
      "Count: 411\n"
     ]
    }
   ],
   "source": [
    "writer = tf.python_io.TFRecordWriter(tfrecord_path)\n",
    "\n",
    "# TODO(user): Write code to read in your dataset to examples variable\n",
    "\n",
    "with open(annot_path) as rb:\n",
    "    annots = json.load(rb)\n",
    "\n",
    "count = 0\n",
    "for annot in annots:\n",
    "    tf_list = create_tf_example(annot)\n",
    "    #break\n",
    "    for tf_example in tf_list:\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "        count += 1\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(\"Count:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n"
     ]
    }
   ],
   "source": [
    "print(len(annots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
